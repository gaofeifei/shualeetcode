第3章	深度学习基础	

一	基本概念
1	神经网络组成
2	25种神经网络有哪些常用模型结构
3	如何选择深度学习开发平台
4	为什么使用深层表示
5	为什么深层神经网络难以训练
6	深度学习和机器学习有什么不同


二	神经网络操作与计算
1	前向传播与反向传播
2	如何计算神经网络的输出
3	如何计算卷积神经网络输出值
4	如何计算Pooling层输出值输出值
5	实例理解反向传播
6	神经网络更“深”有什么意义



三	激活函数
1	为什么需要激活函数
2	为什么激活函数需要非线性函数
3	常见的激活函数及图像
4	常见激活函数的导数计算
5	激活函数有哪些性质
6	如何选择激活函数
7	使用 ReLu 激活函数的优点
8	什么时候可以用线性激活函数
9	怎样理解Relu(<0时)是非线性激活函数
10	Softmax 定义及作用
11	Softmax 函数如何应用于多分类
12	交叉熵代价函数定义及其求导推导
13	为什么Tanh收敛速度比Sigmoid快
14	内聚外斥-Center Loss


四BatchSize
1	为什么需要Batch_Size
2	Batch_Size 值的选择
3	在合理范围内，增大Batch_Size有何好处
4	盲目增大 Batch_Size 有何坏处
5	调节Batch_Size对训练效果影响到底如何


五归一化
1	归一化含义
2	为什么要归一化
3	为什么归一化能提高求解最优解速度
4	归一化有哪些类型
5	局部响应归一化作用
6	理解局部响应归一化
7	什么是批归一化
8	批归一化（BN）算法的优点
9	批归一化（BN）算法流程
10	批归一化和群组归一化比较
11	WeightNormalization和Batch Normalization比较
12	BatchNormalization在什么时候用比较合适


六参数初始化-权重偏差初始化
1	全都初始化为 0
2	全都初始化为同样的值
3	初始化为小的随机数
4	用校准方差
5	稀疏初始化(SparseInitialazation)
6	初始化偏差


七预训练与微调(fine tuning)
1	为什么无监督预训练可以帮助深度学习
2	什么是模型微调fine tuning
3	微调时候网络参数是否更新
4	fine-tuning 模型的三种状态


八超参数
1	什么是超参数
2	如何寻找超参数的最优值
3	超参数搜索一般过程


九学习率
1	学习率的作用
2	学习率衰减常用参数有哪些
3	分段常数衰减
4	指数衰减
5	自然指数衰减
6	多项式衰减
7	余弦衰减


十正则化-Dropout 系列问题
1	为什么要正则化
2	为什么正则化有利于预防过拟合
3	理解dropout正则化 
4	dropout率的选择
5	dropout有什么缺点
6	深度学习中常用的数据增强方法
7	如何理解InternalCovariate Shift



第2章	机器学习基础

一	基本概念
1	各种常见算法都有哪些
2	理解局部最优与全局最优
3	机器学习4种学习方式
4	监督学习有哪些步骤


二	分类算法
1	常用分类算法的优缺点
2	分类算法的评估方法常用术语
3	分类算法的评估评价指标
4	分类算法的评估ROC曲线和PR曲线
5	正确率能很好的评估分类算法吗
6	什么样的分类器是最好的


三	逻辑回归
1	逻辑回归适用性
2	生成模型和判别模型的区别
3	逻辑回归与朴素贝叶斯有什么区别
4	线性回归与逻辑回归的区别


四	代价函数
1	代价函数作用原理
2	平方误差代价函数的主要思想
3	为什么代价函数要非负
4	常见代价函数
5	为什么不用二次方代价函数
6	为什么要用交叉熵

五	损失函数
1	什么是损失函数
2	逻辑回归为什么使用对数损失函数
3	对数损失函数是如何度量损失的
4	代价函数与损失函数的区别


六	梯度下降
1	机器学习中为什么需要梯度下降
2	梯度下降法缺点
3	梯度下降算法的核心思想归纳
4	梯度下降法算法描述
5	如何对梯度下降法进行调优
6	批量梯度下降的求解思路
7	随机梯度下降的求解思路
8	随机梯度和批量梯度区别
9	小批量（Mini-Batch）梯度下降的求解思路
10	各种梯度下降法性能比较
11	自然梯度法
12	Fisher信息矩阵的意义


七	线性判别分析LDA
1	LDA思想总结
2	二类LDA算法原理
3	LDA算法流程总结
4	LDA和PCA区别
5	LDA优缺点


八	主成分分析PCA
1	主成分分析（PCA）思想总结
2	PCA算法流程总结
3	PCA算法主要优缺点
4	降维的必要性及目的
5	KPCA与PCA的区别


九	决策树
1	决策树的基本原理
2	决策树的三要素
3	决策树学习基本算法
4	决策树算法优缺点
5	熵的概念以及理解
6	信息增益的理解
7	决策树中熵，条件熵，信息增益的联系
8	剪枝处理的作用及策略

十	支持向量机
1	什么是支持向量机
2	支持向量机能解决哪些问题
3	核函数特点及其作用
4	SVM为什么引入对偶问题
5	如何理解SVM中的对偶问题
6	常见的核函数有哪些
7	SVM主要特点
8	SVM主要缺点
9	逻辑回归与SVM的异同

十一	贝叶斯分类器
1	极大似然估计原理
2	贝叶斯分类器基本原理
3	朴素贝叶斯分类器
4	半朴素贝叶斯分类器
5	极大似然估计和贝叶斯估计的联系与区别

十二	EM算法
1	EM算法基本思想
2	EM算法流程

十三	降维和聚类
1	为什么会产生维数灾难
2	怎样避免维数灾难
3	聚类和降维有什么区别与联系
4	有哪些聚类算法优劣衡量标准
5	聚类和分类有什么区别
6	四种常用聚类方法之比较


第1章 数学基础
[数学概念]
	标量
	向量
	矩阵
	张量
	导数
	偏导数
	特征值
	特征向量
	概率分布
	随机变量
	离散型随机变量和概率质量函数
	连续型随机变量和概率密度函数
	条件概率
	独立性
	条件独立性
	期望
	方差
	协方差
	相关系数

[问]如何判断一个矩阵为正定
[问]导数和偏导数有什么区别
[问]奇异值与特征值有什么关系
[问]机器学习为什么要使用概率
[问]变量与随机变量有什么区别
[问]随机变量与概率分布的联系
[问]联合概率与边缘概率联系区别  
[问]条件概率的链式法则
[问]常见概率分布
[问]何时采用正态分布


1.6 期望、方差、协方差、相关系数
1期望举例：

2方差举例：

3协方差举例：

4相关系数举例：


